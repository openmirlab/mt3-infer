# MT3-PyTorch Status Report

**Date:** 2025-10-07  
**Status:** ‚úÖ **FULLY WORKING**

## Summary

MT3-PyTorch is now fully functional with both automatic and manual checkpoint download support!

## Test Results

### Performance Metrics
- **Speed:** 5.6x real-time
- **Notes detected:** 767 notes (from 30s test audio)
- **Checkpoint size:** 176MB
- **Load time:** 2.1s (without download), 19.4s (with download)
- **Transcription time:** 5.34s for 29.8s of audio

### Architecture
- **8 encoder/decoder layers** (same as MR-MT3)
- **6 attention heads**
- **d_ff:** 1024
- **vocab_size:** 1536
- **Framework:** PyTorch (no TensorFlow dependency)

## Download Methods

### 1. Automatic Download (Recommended)
Checkpoint downloads automatically when you load the model:

```python
from mt3_infer import load_model

# Auto-download if checkpoint missing
model = load_model('mt3_pytorch', auto_download=True)
midi = model.transcribe(audio, sr=16000)
```

### 2. Manual Download
Pre-download before using the model:

```python
from mt3_infer import download_model, load_model

# Step 1: Download checkpoint
checkpoint_path = download_model('mt3_pytorch')

# Step 2: Load model
model = load_model('mt3_pytorch')
midi = model.transcribe(audio, sr=16000)
```

### 3. Download All Models
Pre-download all available models:

```python
from mt3_infer import download_model

for model_id in ["mr_mt3", "mt3_pytorch", "yourmt3"]:
    download_model(model_id)
```

## Checkpoint Location

Checkpoints are downloaded to: `.mt3_checkpoints/mt3_pytorch/`

This directory is:
- ‚úÖ Located in your project root (not in package directory)
- ‚úÖ Automatically gitignored
- ‚úÖ Shared across all uses of mt3-infer in your project
- ‚úÖ Easy to backup or transfer

## Files Downloaded

```
.mt3_checkpoints/mt3_pytorch/
‚îú‚îÄ‚îÄ config.json     (466 bytes)  - Model configuration
‚îî‚îÄ‚îÄ mt3.pth         (175.2 MB)   - Model weights
```

## Source Repository

Checkpoint source: https://github.com/kunato/mt3-pytorch/tree/master/pretrained

The download system:
1. Clones the repository with Git LFS enabled
2. Extracts only the pretrained/ directory
3. Copies files to `.mt3_checkpoints/mt3_pytorch/`
4. Removes the temporary clone

## Example Usage

See `examples/download_mt3_pytorch.py` for complete examples:

```bash
# Automatic download example
uv run python examples/download_mt3_pytorch.py auto

# Manual download example
uv run python examples/download_mt3_pytorch.py manual

# Download all models
uv run python examples/download_mt3_pytorch.py all
```

## Comparison with MR-MT3

Both models use similar architecture but have different training:

| Feature | MR-MT3 | MT3-PyTorch |
|---------|--------|-------------|
| Speed | 60x real-time | 5.6x real-time |
| Encoder layers | 8 | 8 |
| Decoder layers | 8 | 8 |
| Vocab size | 1536 | 1536 |
| Checkpoint size | 176MB | 176MB |
| Status | ‚úÖ Working | ‚úÖ Working |

## Integration with worzpro-demo

MT3-PyTorch can be used in worzpro-demo:

```python
from mt3_infer import load_model

# In your demo code
model = load_model('mt3_pytorch')
midi = model.transcribe(audio, sr=16000)
```

The checkpoint will be stored in: `/path/to/worzpro-demo/.mt3_checkpoints/mt3_pytorch/`

## Next Steps

- ‚úÖ MR-MT3: Production ready
- ‚úÖ MT3-PyTorch: Production ready with auto-download
- ‚è≥ YourMT3: Needs checkpoint download (522MB)

---

**Status: Production Ready** üéâ
