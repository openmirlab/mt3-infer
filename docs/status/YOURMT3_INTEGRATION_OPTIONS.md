# YourMT3 Integration Options - Feature Comparison

**Date:** 2025-10-07

## Overview

YourMT3 has **94 Python files** across multiple directories. Here's what would be available with each integration approach.

---

## Option 1: Full Vendor Integration

### ‚úÖ Features Kept (Everything)

**All 5 Model Variants:**
1. ‚úÖ YPTF.MoE+Multi (noPS) - 536MB - Default multi-task model
2. ‚úÖ YPTF.MoE+Multi (PS) - 724MB - With pitch shift augmentation
3. ‚úÖ YPTF+Multi (PS) - 517MB - Multi-task with pitch shift
4. ‚úÖ YPTF+Single (noPS) - 345MB - Single-task model
5. ‚úÖ YMT3+ - 518MB - No task conditioning

**Advanced Model Architectures:**
- ‚úÖ Perceiver-TF encoder (cross-attention based)
- ‚úÖ Multi-T5 decoder (26 layers)
- ‚úÖ Mixture of Experts (MoE) feed-forward layers
- ‚úÖ Standard T5 encoder/decoder
- ‚úÖ Conformer encoder support

**Multi-Task Capabilities:**
- ‚úÖ 8-stem separation (drums, bass, guitar, piano, strings, winds, vocals, other)
- ‚úÖ Multi-instrument transcription
- ‚úÖ Simultaneous transcription of multiple instruments
- ‚úÖ Per-channel note extraction

**Advanced Audio Features:**
- ‚úÖ Multiple audio codecs (spectrogram, mel-spectrogram)
- ‚úÖ Configurable hop lengths (128, 300 frames)
- ‚úÖ Variable input frame sizes
- ‚úÖ Pitch shift augmentation (during training/testing)

**Positional Encoding Options:**
- ‚úÖ RoPE (Rotary Position Embedding)
- ‚úÖ ALiBi (Attention with Linear Biases)
- ‚úÖ Trainable positional encoding
- ‚úÖ Sinusoidal encoding
- ‚úÖ Task-dependent positional encoding

**Configuration Flexibility:**
- ‚úÖ Task-conditional encoder/decoder
- ‚úÖ Multiple vocabulary sizes
- ‚úÖ Configurable model dimensions
- ‚úÖ Variable number of layers
- ‚úÖ Different activation functions (GELU, SiLU, ReLU)

**Training Features (if needed later):**
- ‚úÖ PyTorch Lightning training loop
- ‚úÖ Data augmentation pipeline
- ‚úÖ Multiple dataset support
- ‚úÖ Distributed training support
- ‚úÖ Wandb logging integration

### ‚ùå Drawbacks

**Package Size:**
- ‚ùå +94 Python files (~50KB total source code)
- ‚ùå +2.6GB checkpoints (all 5 models)
- ‚ùå Complex dependency tree

**Complexity:**
- ‚ùå PyTorch Lightning dependency (large framework)
- ‚ùå Many configuration files to maintain
- ‚ùå Complex initialization logic
- ‚ùå Harder to debug issues
- ‚ùå Potential dependency conflicts

**Maintenance:**
- ‚ùå Need to keep vendor/ directory in sync with upstream
- ‚ùå More surface area for bugs
- ‚ùå Harder to understand codebase for contributors

---

## Option 2: Simplified Adapter Integration

### ‚úÖ Features Kept (Essential Inference Only)

**Single Default Model:**
- ‚úÖ YPTF.MoE+Multi (noPS) - 536MB
- ‚úÖ Perceiver-TF encoder + Multi-T5 decoder
- ‚úÖ MoE feed-forward layers
- ‚úÖ RoPE positional encoding

**Core Transcription:**
- ‚úÖ Multi-instrument transcription
- ‚úÖ 8-stem separation capability
- ‚úÖ Audio ‚Üí MIDI conversion
- ‚úÖ Note onset/offset detection
- ‚úÖ Velocity estimation
- ‚úÖ Program (instrument) detection

**Audio Processing:**
- ‚úÖ Spectrogram feature extraction
- ‚úÖ 300-frame hop length
- ‚úÖ Audio segmentation
- ‚úÖ Automatic resampling to 16kHz

**Post-Processing:**
- ‚úÖ Multi-channel detokenization
- ‚úÖ Note event merging
- ‚úÖ Tie note handling
- ‚úÖ MIDI file generation

**Integration:**
- ‚úÖ Fits MT3Base interface
- ‚úÖ Auto-download checkpoint
- ‚úÖ Device auto-detection (CPU/GPU)
- ‚úÖ Simple transcribe() API

### ‚ö†Ô∏è Features Lost (Advanced/Training Features)

**Model Variants:**
- ‚ùå Can't switch to other 4 checkpoint variants
- ‚ùå No pitch shift model option
- ‚ùå No single-task model option
- ‚ùå Can't use YMT3+ variant

**Architecture Flexibility:**
- ‚ùå Can't switch encoder types (T5, Conformer)
- ‚ùå Can't switch decoder types
- ‚ùå No runtime architecture configuration
- ‚ùå Fixed positional encoding type

**Advanced Features:**
- ‚ùå No pitch shift augmentation
- ‚ùå Can't change audio codec at runtime
- ‚ùå Can't adjust hop length dynamically
- ‚ùå No custom vocabulary support

**Training/Fine-tuning:**
- ‚ùå No training capability
- ‚ùå No PyTorch Lightning integration
- ‚ùå No data augmentation
- ‚ùå Can't fine-tune on custom data

**Configuration:**
- ‚ùå Limited runtime configuration
- ‚ùå Can't change task conditioning
- ‚ùå Fixed model dimensions
- ‚ùå No experiment management

### üì¶ What Gets Vendored (Minimal Set)

**Required Files (~20-30 files):**
```
mt3_infer/vendor/yourmt3/
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îú‚îÄ‚îÄ ymt3.py              # Main model class
‚îÇ   ‚îú‚îÄ‚îÄ perceiver_tf.py      # Perceiver encoder
‚îÇ   ‚îú‚îÄ‚îÄ multi_t5.py          # Multi-T5 decoder
‚îÇ   ‚îî‚îÄ‚îÄ moe.py               # Mixture of Experts
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ task_manager.py      # Tokenizer/detokenizer
‚îÇ   ‚îú‚îÄ‚îÄ audio.py             # Audio preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ midi.py              # MIDI utilities
‚îÇ   ‚îú‚îÄ‚îÄ event_codec.py       # Event encoding/decoding
‚îÇ   ‚îú‚îÄ‚îÄ event2note.py        # Event ‚Üí Note conversion
‚îÇ   ‚îú‚îÄ‚îÄ note2event.py        # Note ‚Üí Event conversion
‚îÇ   ‚îî‚îÄ‚îÄ tokenizer.py         # Token management
‚îî‚îÄ‚îÄ config/
    ‚îú‚îÄ‚îÄ config.py            # Model configuration
    ‚îú‚îÄ‚îÄ task.py              # Task definitions
    ‚îî‚îÄ‚îÄ vocabulary.py        # Vocabulary presets
```

**Simplified Adapter:**
```python
# mt3_infer/adapters/yourmt3.py (~200-300 lines)
from mt3_infer.base import MT3Base
from mt3_infer.vendor.yourmt3 import YourMT3, TaskManager

class YourMT3Adapter(MT3Base):
    def load_model(self, checkpoint_path, device="auto"):
        # Load default YPTF.MoE+Multi (noPS) model
        # Fixed configuration, no runtime changes

    def preprocess(self, audio, sr):
        # Spectrogram extraction, 300-frame hop

    def forward(self, features):
        # Run inference with bsz=8

    def decode(self, outputs):
        # Multi-channel detokenization ‚Üí MIDI
```

**Dependencies:**
- ‚úÖ pytorch-lightning (only for model class, not trainer)
- ‚úÖ No extra dependencies beyond existing mt3-infer

---

## Feature Comparison Table

| Feature | Option 1 (Full) | Option 2 (Simplified) | Lost in Option 2 |
|---------|----------------|----------------------|------------------|
| **Models** | 5 variants | 1 default | 4 other variants |
| **Encoder types** | 3 (T5, Perceiver-TF, Conformer) | 1 (Perceiver-TF) | T5, Conformer |
| **Decoder types** | 2 (T5, Multi-T5) | 1 (Multi-T5) | T5 |
| **Positional encoding** | 8+ types | 1 (RoPE) | 7 other types |
| **Audio codecs** | 2 (spec, melspec) | 1 (spec) | melspec |
| **Hop lengths** | Configurable | Fixed (300) | Runtime config |
| **Multi-task** | ‚úÖ Full | ‚úÖ Full | None |
| **8-stem separation** | ‚úÖ | ‚úÖ | None |
| **Pitch shift aug** | ‚úÖ | ‚ùå | Training feature |
| **Training support** | ‚úÖ | ‚ùå | Training entirely |
| **Runtime config** | ‚úÖ Full | ‚ö†Ô∏è Limited | Most config |
| **Package size** | 94 files, 2.6GB | ~25 files, 536MB | 69 files, 2.1GB |
| **Complexity** | Very high | Medium | N/A |
| **Maintenance** | High effort | Medium effort | N/A |

---

## Practical Impact for Users

### What Users CAN Do with Option 2:

‚úÖ **Transcribe any music audio** with YourMT3's best model
‚úÖ **Separate 8 instrument stems** and get per-stem MIDI
‚úÖ **Get high-quality transcriptions** with MoE model
‚úÖ **Use same API** as MR-MT3 and MT3-PyTorch:
```python
from mt3_infer import load_model

model = load_model('yourmt3')  # Auto-downloads 536MB
midi = model.transcribe(audio, sr=16000)
```

### What Users CANNOT Do with Option 2:

‚ùå Switch to a different YourMT3 checkpoint variant
‚ùå Use pitch shift augmentation
‚ùå Change encoder/decoder architecture at runtime
‚ùå Fine-tune the model on their own data
‚ùå Use T5-only encoder instead of Perceiver-TF
‚ùå Change positional encoding type
‚ùå Use mel-spectrogram instead of spectrogram

### Are These Limitations Critical?

**For 95% of users:** ‚ùå **No, not critical**
- The default YPTF.MoE+Multi (noPS) is the **best model** in the collection
- Most users just want: audio in ‚Üí MIDI out
- Advanced features are mainly for researchers/developers

**For power users:** ‚ö†Ô∏è **Maybe, but workarounds exist**
- Can use full YourMT3 repo separately if needed
- Can request Option 1 (full vendor) in v0.2.0
- Can manually load checkpoints via refs/yourmt3/

---

## Recommendation: Option 2 (Simplified)

### Why Option 2 is Best for v0.1.0:

1. **‚úÖ Keeps core features:** Multi-task, 8-stem separation, high quality
2. **‚úÖ Reasonable size:** 536MB vs 2.6GB (5x smaller)
3. **‚úÖ Manageable complexity:** ~25 files vs 94 files
4. **‚úÖ Faster to implement:** Can be done in v0.1.0
5. **‚úÖ Easy to upgrade:** Can add Option 1 features in v0.2.0

### What Gets Lost is Acceptable:

- **Other model variants:** Default is the best one anyway
- **Architecture flexibility:** Users want results, not config
- **Training features:** mt3-infer is inference-only by design
- **Advanced config:** Simplicity > flexibility for most users

### Path Forward:

**v0.1.0 (Now):**
- ‚úÖ MR-MT3: Speed champion (22.7x RT)
- ‚úÖ MT3-PyTorch: Accuracy champion (767 notes)
- ‚úÖ YourMT3 (simplified): Multi-task champion (8-stem separation)

**v0.2.0 (Future, if needed):**
- ‚è≥ YourMT3 full vendor (all 5 models, full features)
- ‚è≥ Magenta MT3 (JAX/Flax, original implementation)
- ‚è≥ Training/fine-tuning support

---

## Implementation Estimate

### Option 1 (Full Vendor):
- **Time:** 2-3 days
- **Risk:** High (dependency conflicts, complex debugging)
- **Code:** ~94 files vendored + adapter
- **Testing:** Extensive (multiple models, configurations)

### Option 2 (Simplified):
- **Time:** 4-6 hours
- **Risk:** Medium (need to extract essential code correctly)
- **Code:** ~25 files vendored + adapter
- **Testing:** Moderate (single model, fixed config)

---

**Recommendation: Go with Option 2 for v0.1.0** ‚úÖ

Users get 95% of the value with 25% of the complexity.
