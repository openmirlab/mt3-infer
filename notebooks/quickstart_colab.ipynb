{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MT3-Infer - Music Transcription\n",
    "\n",
    "This notebook demonstrates how to use MT3-Infer for transcribing music audio to MIDI.\n",
    "\n",
    "**Features:**\n",
    "- Transcribe audio to MIDI automatically\n",
    "- Multiple pre-trained models available (MR-MT3, MT3-PyTorch, YourMT3)\n",
    "- High-quality music transcription using transformer architecture"
   ],
   "metadata": {
    "id": "cell-0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Installation"
   ],
   "metadata": {
    "id": "cell-1"
   }
  },
  {
   "cell_type": "code",
   "source": "# Install mt3-infer with synthesis support\n!pip install -q \"mt3-infer[synthesis] @ git+https://github.com/openmirlab/mt3-infer.git\" soundfile\n!apt-get -qq install -y fluidsynth",
   "metadata": {
    "id": "cell-2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Verify installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ],
   "metadata": {
    "id": "cell-3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Download Model\n",
    "\n",
    "We'll use the **MR-MT3** model, which is optimized for speed (57x real-time)."
   ],
   "metadata": {
    "id": "cell-4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create directories\n",
    "!mkdir -p input_songs\n",
    "!mkdir -p outputs"
   ],
   "metadata": {
    "id": "cell-5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Download and cache the model (models are automatically downloaded on first use)\n",
    "from mt3_infer import download_model, list_models\n",
    "\n",
    "model_name = \"mr_mt3\"  # Fast model (57x real-time)\n",
    "print(f\"Downloading model: {model_name}\")\n",
    "print(\"(This may take a few minutes on first run)\\n\")\n",
    "\n",
    "checkpoint_path = download_model(model_name)\n",
    "\n",
    "print(f\"\\nModel downloaded successfully!\")\n",
    "print(f\"Checkpoint: {checkpoint_path}\")"
   ],
   "metadata": {
    "id": "cell-6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Upload Your Audio File\n",
    "\n",
    "Upload a `.wav` file to transcribe to MIDI."
   ],
   "metadata": {
    "id": "cell-7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Option 1: Upload from your computer\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload your audio file (.wav format):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move uploaded file to input folder\n",
    "for filename in uploaded.keys():\n",
    "    !mv \"{filename}\" input_songs/\n",
    "    print(f\"Moved {filename} to input_songs/\")"
   ],
   "metadata": {
    "id": "cell-8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Option 2: Use a sample audio (uncomment to use)\n",
    "# !wget -q -O input_songs/sample.wav \"YOUR_AUDIO_URL_HERE\""
   ],
   "metadata": {
    "id": "cell-9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Check input files\n",
    "!ls -lh input_songs/"
   ],
   "metadata": {
    "id": "cell-10"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Run Music Transcription\n",
    "\n",
    "Select your preferred method and run the transcription:"
   ],
   "metadata": {
    "id": "cell-11"
   }
  },
  {
   "cell_type": "code",
   "source": "#@title Select Inference Options { display-mode: \"form\" }\n#@markdown Choose inference method and device:\n\ninference_method = \"CLI (Command Line)\" #@param [\"CLI (Command Line)\", \"Python API\"]\ndevice = \"cpu\" #@param [\"auto\", \"cuda\", \"cpu\"]\n\nprint(f\"Selected method: {inference_method}\")\nprint(f\"Selected device: {device}\")",
   "metadata": {
    "id": "cell-12"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#@title Run Music Transcription { display-mode: \"form\" }\n#@markdown Click the play button to run transcription with your selected method.\n\nfrom pathlib import Path\n\nif inference_method == \"CLI (Command Line)\":\n    # ============================================\n    # Option A: CLI (Command Line)\n    # ============================================\n    print(\"Running with CLI...\\n\")\n    \n    input_folder = Path(\"input_songs\")\n    for audio_file in input_folder.glob(\"*.wav\"):\n        output_file = Path(\"outputs\") / f\"{audio_file.stem}.mid\"\n        !mt3-infer transcribe \"{audio_file}\" -o \"{output_file}\" -m mr_mt3 --device {device}\n\nelse:\n    # ============================================\n    # Option B: Python API\n    # ============================================\n    print(\"Running with Python API...\\n\")\n\n    from mt3_infer.utils.audio import load_audio\n    from mt3_infer import download_model\n    from mt3_infer.adapters.mr_mt3 import MRMT3Adapter\n\n    # Load model\n    checkpoint_path = download_model(\"mr_mt3\")\n    adapter = MRMT3Adapter()\n    adapter.load_model(checkpoint_path, device=device)\n\n    # Process files\n    input_folder = Path(\"input_songs\")\n    output_folder = Path(\"outputs\")\n    output_folder.mkdir(exist_ok=True)\n\n    for audio_path in input_folder.glob(\"*.wav\"):\n        print(f\"Processing: {audio_path.name}\")\n\n        # Load audio\n        audio, sr = load_audio(str(audio_path), sr=16000)\n\n        # Run transcription\n        midi = adapter.transcribe(audio, sr)\n\n        # Save MIDI\n        output_path = output_folder / f\"{audio_path.stem}.mid\"\n        midi.save(str(output_path))\n        print(f\"  Saved: {output_path}\")\n\n    print(\"\\nDone!\")",
   "metadata": {
    "id": "cell-13"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Check Output Files"
   ],
   "metadata": {
    "id": "cell-14"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Check output files\n",
    "!ls -lh outputs/"
   ],
   "metadata": {
    "id": "cell-15"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Preview Results"
   ],
   "metadata": {
    "id": "cell-16"
   }
  },
  {
   "cell_type": "code",
   "source": "#@title Preview MIDI Results { display-mode: \"form\" }\n#@markdown This cell displays MIDI info and synthesizes audio for playback.\n\nimport pretty_midi\nimport numpy as np\nfrom pathlib import Path\nimport IPython.display as ipd\n\n# Download a General MIDI soundfont if not exists\nsoundfont_path = \"/usr/share/sounds/sf2/FluidR3_GM.sf2\"\nif not Path(soundfont_path).exists():\n    print(\"Downloading soundfont...\")\n    !wget -q -O /tmp/FluidR3_GM.sf2 \"https://keymusician01.s3.amazonaws.com/FluidR3_GM.sf2\"\n    !mkdir -p /usr/share/sounds/sf2\n    !mv /tmp/FluidR3_GM.sf2 /usr/share/sounds/sf2/\n    print(\"Soundfont ready!\")\n\noutput_dir = Path(\"outputs\")\n\n# Find and display all output files\nfor midi_file in sorted(output_dir.glob(\"*.mid\")):\n    print(f\"\\n{'='*60}\")\n    print(f\"File: {midi_file.name}\")\n    print(f\"{'='*60}\")\n    \n    # Load and display MIDI info\n    midi_data = pretty_midi.PrettyMIDI(str(midi_file))\n    print(f\"Duration: {midi_data.get_end_time():.2f} seconds\")\n    print(f\"Tempo: {midi_data.estimate_tempo():.1f} BPM\")\n    print(f\"Instruments: {len(midi_data.instruments)}\")\n    \n    total_notes = sum(len(inst.notes) for inst in midi_data.instruments)\n    print(f\"Total notes: {total_notes}\")\n    \n    for inst in midi_data.instruments:\n        if inst.is_drum:\n            inst_name = \"Drums\"\n        else:\n            inst_name = pretty_midi.program_to_instrument_name(inst.program)\n        print(f\"  - {inst_name}: {len(inst.notes)} notes\")\n    \n    # Synthesize MIDI to audio\n    print(f\"\\nSynthesizing audio...\")\n    try:\n        from midi2audio import FluidSynth\n        \n        audio_output = f\"/tmp/{midi_file.stem}_synth.wav\"\n        fs = FluidSynth(soundfont_path)\n        fs.midi_to_audio(str(midi_file), audio_output)\n        \n        print(\"Play synthesized MIDI:\")\n        display(ipd.Audio(audio_output))\n    except Exception as e:\n        print(f\"Synthesis failed: {e}\")\n        print(\"Falling back to pretty_midi synthesis...\")\n        try:\n            # Fallback: use pretty_midi's built-in synthesizer\n            audio_data = midi_data.fluidsynth(fs=44100)\n            print(\"Play synthesized MIDI:\")\n            display(ipd.Audio(audio_data, rate=44100))\n        except Exception as e2:\n            print(f\"Fallback also failed: {e2}\")",
   "metadata": {
    "id": "cell-17"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Download Results"
   ],
   "metadata": {
    "id": "cell-18"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Download all output files as a zip\n",
    "!zip -r outputs.zip outputs/\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"outputs.zip\")"
   ],
   "metadata": {
    "id": "cell-19"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Available Models\n",
    "\n",
    "| Model | Speed | Notes Detected | Size | Best For |\n",
    "|-------|-------|----------------|------|----------|\n",
    "| MR-MT3 | 57x real-time | 116 notes | 176 MB | Speed (recommended) |\n",
    "| MT3-PyTorch | 12x real-time | 147 notes | 176 MB | Accuracy |\n",
    "| YourMT3 | ~15x real-time | 118 notes | 536 MB | Multi-stem separation |\n",
    "\n",
    "See the [GitHub repository](https://github.com/openmirlab/mt3-infer) for more options."
   ],
   "metadata": {
    "id": "cell-20"
   }
  }
 ]
}